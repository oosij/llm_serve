# llm_serve
![녹화4](https://github.com/user-attachments/assets/785d2dd3-ea55-4e44-aebf-366adfbc9e44)




Docker 기반의 LLM 서버 및 sLLM FT 서버와 RAG 연구 서버를 설정하여 실시간 API 서빙 및 연구 개발 진행, Streamlit 대시보드로 임의 구현


## 개선사항 및 연구 개발 
- 검색 최적화를 위해 다양한 RAG 기술과 벡터 데이터베이스를 활용
- CoT 기반 sLLM 추론을 통해 성능 향상
- 검색 정확도와 응답성을 높이기 위한 지속적인 연구 진행 중 
